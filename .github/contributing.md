# Welcome to the Spark-Database Contributing Document
This file will overview the role of the software used by spark-database, how to set up a local version of the repository, and how to contribute to the development and maintainence of the project. Command Line instructions will assume use of Linux or Windows Subsystem(WLS) for Linux. Instructions for the Setup of Mac can be found at **Link** or **Military Link**

## Using the Database
* Link back to Readme

## Overview Programming Concepts
* Spark-Website Wiki
- Developer Tools
- Version Control
- Initial Machine Setup

## Python
* Role of Python: Open Source, Machine Learning, Web Development
* Versions 3 is the most current. It is used in Spark-Database program. Version 2 is still maintained

## Python3 Installation Commands
```sudo apt-get update``
```sudo apt-get python3```

## Relational Databases
* Purpose of Relational Databases
* Real World Implications
* Software Applications

## Database Engines
* Maria
* sqlite
* postgresql
* mysql
* sql

## PostgreSQL installation Commands
* install postgresql
* create password
* create spark-database 
* Stale PID: pg_ctlcluster 10 main start

## [GitHub Intructions](Main GitHub tutorial)
- [Spark-Website Wiki Version](local link)
- Fork
- Clone
- Add Upstream

## [Virtual Environment](Link to Overview)
* Purpose
* Importance
* Docker is becoming a new standard

## Create Virtual Environment
* Initialize
* Start
* Install Requirements
* pip
* install requirements

## [SQLAlchemy](Main Documentation)
* Purpose
* Importance

## [Alembic](Link to Alembic Tutorial)
* Importance of Migrating databases
* Initialize the user table

## [Linting](Link to pylint tutorial)
* Importance of Linting
* Commands to lint files, before submitting pull requests

## [Pick](Link to Pick)
* Utilization of Pick to go beyond text inputs
